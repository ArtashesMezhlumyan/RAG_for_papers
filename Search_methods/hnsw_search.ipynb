{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artashesmezhlumyan/Desktop/capstone/capstonevenv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/artashesmezhlumyan/Desktop/capstone/capstonevenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from hnswlib import Index\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "import pickle\n",
    "import hnswlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artashesmezhlumyan/Desktop/capstone/capstonevenv/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosie search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "384\n",
      "<class 'numpy.ndarray'>\n",
      "(3, 384)\n",
      "Top 3 similar sentences are:\n",
      "1. ('  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n', 0.028408825397491455)\n",
      "2. (\"  The evolution of Earth-Moon system is described by the dark matter field\\nfluid model proposed in the Meeting of Division of Particle and Field 2004,\\nAmerican Physical Society. The current behavior of the Earth-Moon system agrees\\nwith this model very well and the general pattern of the evolution of the\\nMoon-Earth system described by this model agrees with geological and fossil\\nevidence. The closest distance of the Moon to Earth was about 259000 km at 4.5\\nbillion years ago, which is far beyond the Roche's limit. The result suggests\\nthat the tidal friction may not be the primary cause for the evolution of the\\nEarth-Moon system. The average dark matter field fluid constant derived from\\nEarth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts\\nthat the Mars's rotation is also slowing with the angular acceleration rate\\nabout -4.38 x 10^(-22) rad s^(-2).\\n\", -0.007543206214904785)\n",
      "3. ('  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n', -0.016365528106689453)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def search_similar_sentences(query, index, doc_list, k=5):\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    labels, distances = index.knn_query(query_embedding, k=k)\n",
    "    similar_sentences_with_scores = [(doc_list[label], 1 - distance) for label, distance in zip(labels[0], distances[0])]\n",
    "\n",
    "    return similar_sentences_with_scores\n",
    "\n",
    "\n",
    "with open(\"embeddings.pkl\", \"rb\") as fIn:\n",
    "    stored_data = pickle.load(fIn)\n",
    "    stored_sentences = stored_data[\"sentences\"]\n",
    "    stored_embeddings = stored_data[\"embeddings\"]\n",
    "\n",
    "# Ensure stored_embeddings is on CPU and converted to NumPy\n",
    "if isinstance(stored_embeddings, torch.Tensor):\n",
    "    stored_embeddings = stored_embeddings.cpu().numpy()  # Convert to CPU and NumPy array\n",
    "print(stored_embeddings.shape)\n",
    "dimension = stored_embeddings.shape[1]\n",
    "print(dimension)\n",
    "p = hnswlib.Index(space='cosine', dim=dimension)\n",
    "p.init_index(max_elements=10000, ef_construction=200, M=16)\n",
    "print(type(stored_embeddings))\n",
    "print(stored_embeddings.shape)\n",
    "p.add_items(stored_embeddings)  # Now stored_embeddings is a NumPy array on CPU\n",
    "p.set_ef(50)  # Setting ef, which controls the recall\n",
    "\n",
    "new_sentence = \"My sister's leg broke\"\n",
    "top_similar_sentences = search_similar_sentences(new_sentence, p, stored_sentences, k=3)\n",
    "\n",
    "print(\"Top 3 similar sentences are:\")\n",
    "for i, sentence in enumerate(top_similar_sentences):\n",
    "    print(f\"{i+1}. {sentence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 similar sentences are:\n",
      "1. ('  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n', 0.026975154876708984)\n",
      "2. (\"  The evolution of Earth-Moon system is described by the dark matter field\\nfluid model proposed in the Meeting of Division of Particle and Field 2004,\\nAmerican Physical Society. The current behavior of the Earth-Moon system agrees\\nwith this model very well and the general pattern of the evolution of the\\nMoon-Earth system described by this model agrees with geological and fossil\\nevidence. The closest distance of the Moon to Earth was about 259000 km at 4.5\\nbillion years ago, which is far beyond the Roche's limit. The result suggests\\nthat the tidal friction may not be the primary cause for the evolution of the\\nEarth-Moon system. The average dark matter field fluid constant derived from\\nEarth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts\\nthat the Mars's rotation is also slowing with the angular acceleration rate\\nabout -4.38 x 10^(-22) rad s^(-2).\\n\", -0.006630659103393555)\n",
      "3. ('  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n', -0.013648390769958496)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def search_similar_sentences(query, index, doc_list, k=5):\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    labels, distances = index.knn_query(query_embedding, k=k)\n",
    "    similar_sentences_with_scores = [(doc_list[label], 1 - distance) for label, distance in zip(labels[0], distances[0])]\n",
    "\n",
    "    return similar_sentences_with_scores\n",
    "\n",
    "\n",
    "with open(\"embeddings.pkl\", \"rb\") as fIn:\n",
    "    stored_data = pickle.load(fIn)\n",
    "    stored_sentences = stored_data[\"sentences\"]\n",
    "    stored_embeddings = stored_data[\"embeddings\"]\n",
    "\n",
    "# Ensure stored_embeddings is on CPU and converted to NumPy\n",
    "if isinstance(stored_embeddings, torch.Tensor):\n",
    "    stored_embeddings = stored_embeddings.cpu().numpy()  # Convert to CPU and NumPy array\n",
    "\n",
    "dimension = stored_embeddings.shape[1]\n",
    "p = hnswlib.Index(space='ip', dim=dimension)\n",
    "p.init_index(max_elements=10000, ef_construction=200, M=16)\n",
    "p.add_items(stored_embeddings)  # Now stored_embeddings is a NumPy array on CPU\n",
    "p.set_ef(50)  # Setting ef, which controls the recall\n",
    "\n",
    "new_sentence = \"My sister's leg broke\"\n",
    "top_similar_sentences = search_similar_sentences(new_sentence, p, stored_sentences, k=3)\n",
    "\n",
    "print(\"Top 3 similar sentences are:\")\n",
    "for i, sentence in enumerate(top_similar_sentences):\n",
    "    print(f\"{i+1}. {sentence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 similar sentences are:\n",
      "1. ('  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n', -0.7228014469146729)\n",
      "2. (\"  The evolution of Earth-Moon system is described by the dark matter field\\nfluid model proposed in the Meeting of Division of Particle and Field 2004,\\nAmerican Physical Society. The current behavior of the Earth-Moon system agrees\\nwith this model very well and the general pattern of the evolution of the\\nMoon-Earth system described by this model agrees with geological and fossil\\nevidence. The closest distance of the Moon to Earth was about 259000 km at 4.5\\nbillion years ago, which is far beyond the Roche's limit. The result suggests\\nthat the tidal friction may not be the primary cause for the evolution of the\\nEarth-Moon system. The average dark matter field fluid constant derived from\\nEarth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts\\nthat the Mars's rotation is also slowing with the angular acceleration rate\\nabout -4.38 x 10^(-22) rad s^(-2).\\n\", -0.7859638929367065)\n",
      "3. ('  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n', -0.8476673364639282)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def search_similar_sentences(query, index, doc_list, k=5):\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    labels, distances = index.knn_query(query_embedding, k=k)\n",
    "    similar_sentences_with_scores = [(doc_list[label], 1 - distance) for label, distance in zip(labels[0], distances[0])]\n",
    "\n",
    "    return similar_sentences_with_scores\n",
    "\n",
    "\n",
    "with open(\"embeddings.pkl\", \"rb\") as fIn:\n",
    "    stored_data = pickle.load(fIn)\n",
    "    stored_sentences = stored_data[\"sentences\"]\n",
    "    stored_embeddings = stored_data[\"embeddings\"]\n",
    "\n",
    "# Ensure stored_embeddings is on CPU and converted to NumPy\n",
    "if isinstance(stored_embeddings, torch.Tensor):\n",
    "    stored_embeddings = stored_embeddings.cpu().numpy()  # Convert to CPU and NumPy array\n",
    "\n",
    "dimension = stored_embeddings.shape[1]\n",
    "p = hnswlib.Index(space='l2', dim=dimension)\n",
    "p.init_index(max_elements=10000, ef_construction=200, M=16)\n",
    "p.add_items(stored_embeddings)  # Now stored_embeddings is a NumPy array on CPU\n",
    "p.set_ef(50)  # Setting ef, which controls the recall\n",
    "\n",
    "new_sentence = \"My sister's leg broke\"\n",
    "top_similar_sentences = search_similar_sentences(new_sentence, p, stored_sentences, k=3)\n",
    "\n",
    "print(\"Top 3 similar sentences are:\")\n",
    "for i, sentence in enumerate(top_similar_sentences):\n",
    "    print(f\"{i+1}. {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbotvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
